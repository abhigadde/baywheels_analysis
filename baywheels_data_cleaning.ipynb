{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c766dc",
   "metadata": {},
   "source": [
    "Goals for this code\n",
    "1. Take a look at the fields in the Ford and Lyft data\n",
    "2. Determine what fields are useful to me\n",
    "3. Determine how to combine them, since both datasets have some different field and field names\n",
    "\n",
    "BONUS: Make sure my S3 AWS bucket can be accessed by anyone and provide instructions on access credentials so they can easily download it\n",
    "\n",
    "BONUS 2: Complete in google collabs so easier for anyone to pickup and run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2782228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will utilize some code from my past web scraping project and tweak it for this project.\n",
    "#I will use selenium since that is what I have used in the past and is what I am familiar with\n",
    "\n",
    "#This currently looks up certain fields for you and enters them into the website. \n",
    "#Next would be to automate this to run through all 4 designations I want. Do that at end. Also make cleaner later.\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import math\n",
    "import regex as re \n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import boto3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60ca0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data from S3 and store in aws_data folder\n",
    "#we already have a copy locally but for other users who don't this code will be helpful\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Create an S3 access object\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "s3.download_file(\n",
    "    Bucket=\"baywheels.data\", Key=\"ford_data.csv\", Filename=\"aws_data/ford_data_download.csv\"\n",
    ")\n",
    "\n",
    "s3.download_file(\n",
    "    Bucket=\"baywheels.data\", Key=\"lyft_data.csv\", Filename=\"aws_data/lyft_data_download.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f7d306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadde\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\gadde\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2,3,4,8,13,14,15,16,17,18,19,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#Let us start by taking a look at the ford data\n",
    "df_ford = pd.read_csv('aws_data/ford_data_download.csv')\n",
    "df_lyft = pd.read_csv('aws_data/lyft_data_download.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d9b3568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ford dataset data types: \n",
      "Unnamed: 0                   int64\n",
      "duration_sec                 int64\n",
      "start_time                  object\n",
      "end_time                    object\n",
      "start_station_id           float64\n",
      "start_station_name          object\n",
      "start_station_latitude     float64\n",
      "start_station_longitude    float64\n",
      "end_station_id             float64\n",
      "end_station_name            object\n",
      "end_station_latitude       float64\n",
      "end_station_longitude      float64\n",
      "bike_id                      int64\n",
      "user_type                   object\n",
      "bike_share_for_all_trip     object\n",
      "dtype: object\n",
      "\n",
      "lyft dataset data types: \n",
      "Unnamed: 0                   int64\n",
      "duration_sec               float64\n",
      "start_time                  object\n",
      "end_time                    object\n",
      "start_station_id            object\n",
      "start_station_name          object\n",
      "start_station_latitude     float64\n",
      "start_station_longitude    float64\n",
      "end_station_id              object\n",
      "end_station_name            object\n",
      "end_station_latitude       float64\n",
      "end_station_longitude      float64\n",
      "bike_id                    float64\n",
      "user_type                   object\n",
      "bike_share_for_all_trip     object\n",
      "rental_access_method        object\n",
      "ride_id                     object\n",
      "rideable_type               object\n",
      "started_at                  object\n",
      "ended_at                    object\n",
      "start_lat                  float64\n",
      "start_lng                  float64\n",
      "end_lat                    float64\n",
      "end_lng                    float64\n",
      "member_casual               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Looking at the data types there are a lot of objects that we should change into actual data types\n",
    "print('ford dataset data types: ')\n",
    "print(df_ford.dtypes)\n",
    "print('\\nlyft dataset data types: ')\n",
    "print(df_lyft.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af6f2fc",
   "metadata": {},
   "source": [
    "I have decided to include the following fields in my first-run analysis\n",
    "1. duration_sec\n",
    "2. start_time /  started_at                \n",
    "3. end_time / ended_at\n",
    "4. user_type / member_casual\n",
    "5. bike_share_for_all_trip\n",
    "\n",
    "Reasons for choice\n",
    "1. Want fields present in both datasets to have longest running data possible\n",
    "2. Want to limit analysis really to duration and time of day - which is why station info was excluded\n",
    "\n",
    "Note we may choose to include more fields in a later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40091d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only columns of interest\n",
    "col_ford = ['start_time','end_time','user_type','bike_share_for_all_trip']\n",
    "df_ford_trim = pd.DataFrame()\n",
    "df_ford_trim = df_ford[col_ford]\n",
    "\n",
    "col_lyft = ['start_time','started_at','end_time','ended_at','user_type', 'member_casual','bike_share_for_all_trip']\n",
    "df_lyft_trim = pd.DataFrame()\n",
    "df_lyft_trim = df_lyft[col_lyft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a100d990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_6880/782311638.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lyft_trim['start_time'] = df_lyft_trim['start_time'].fillna(df_lyft_trim['started_at'])\n",
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_6880/782311638.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lyft_trim['end_time'] = df_lyft_trim['end_time'].fillna(df_lyft_trim['ended_at'])\n",
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_6880/782311638.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lyft_trim['user_type'] = df_lyft_trim['user_type'].fillna(df_lyft_trim['member_casual'])\n"
     ]
    }
   ],
   "source": [
    "#Combine the time columns for the lyft data. Let us use fillna\n",
    "df_lyft_trim['start_time'] = df_lyft_trim['start_time'].fillna(df_lyft_trim['started_at'])\n",
    "df_lyft_trim['end_time'] = df_lyft_trim['end_time'].fillna(df_lyft_trim['ended_at'])\n",
    "df_lyft_trim['user_type'] = df_lyft_trim['user_type'].fillna(df_lyft_trim['member_casual'])\n",
    "\n",
    "#now drop the alternate named columns since combined\n",
    "df_lyft_trim = df_lyft_trim.drop(['started_at', 'ended_at', 'member_casual'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f8e6081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>user_type</th>\n",
       "      <th>bike_share_for_all_trip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3254320</th>\n",
       "      <td>2019-04-01 00:09:17.5660</td>\n",
       "      <td>2019-04-01 00:12:22.5170</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254321</th>\n",
       "      <td>2019-04-01 00:03:02.5730</td>\n",
       "      <td>2019-04-01 00:12:02.0670</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254322</th>\n",
       "      <td>2019-04-01 00:06:04.2370</td>\n",
       "      <td>2019-04-01 00:10:56.9850</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254323</th>\n",
       "      <td>2019-04-01 00:01:38.4110</td>\n",
       "      <td>2019-04-01 00:09:29.9650</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254324</th>\n",
       "      <td>2019-04-01 00:00:28.7290</td>\n",
       "      <td>2019-04-01 00:06:25.0650</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       start_time                  end_time   user_type  \\\n",
       "3254320  2019-04-01 00:09:17.5660  2019-04-01 00:12:22.5170  Subscriber   \n",
       "3254321  2019-04-01 00:03:02.5730  2019-04-01 00:12:02.0670  Subscriber   \n",
       "3254322  2019-04-01 00:06:04.2370  2019-04-01 00:10:56.9850  Subscriber   \n",
       "3254323  2019-04-01 00:01:38.4110  2019-04-01 00:09:29.9650  Subscriber   \n",
       "3254324  2019-04-01 00:00:28.7290  2019-04-01 00:06:25.0650  Subscriber   \n",
       "\n",
       "        bike_share_for_all_trip  \n",
       "3254320                      No  \n",
       "3254321                     Yes  \n",
       "3254322                     Yes  \n",
       "3254323                     Yes  \n",
       "3254324                      No  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ford_trim.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d43bf3a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_6880/2406727157.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ford_trim['start_time'] = pd.to_datetime(df_ford_trim['start_time'])\n",
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_6880/2406727157.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ford_trim['end_time'] = pd.to_datetime(df_ford_trim['end_time'])\n"
     ]
    }
   ],
   "source": [
    "#Change column data types from object to more reasonable values\n",
    "df_ford_trim['start_time'] = pd.to_datetime(df_ford_trim['start_time'])\n",
    "df_ford_trim['end_time'] = pd.to_datetime(df_ford_trim['end_time'])\n",
    "df_lyft_trim['start_time'] = pd.to_datetime(df_lyft_trim['start_time'])\n",
    "df_lyft_trim['end_time'] = pd.to_datetime(df_lyft_trim['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b371bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#union the 2 df\n",
    "df = pd.concat([df_ford_trim, df_lyft_trim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2be70079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -1 days +01:44:49.409000\n",
       "1         -1 days +02:06:39.225000\n",
       "2         -1 days +11:17:11.528000\n",
       "3         -1 days +06:43:47.105000\n",
       "4         -1 days +11:53:16.430000\n",
       "                    ...           \n",
       "6564180          -1 days +23:24:19\n",
       "6564181          -1 days +23:55:47\n",
       "6564182          -1 days +23:46:37\n",
       "6564183          -1 days +23:58:31\n",
       "6564184          -1 days +23:36:00\n",
       "Length: 9818510, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['start_time'] - df['end_time'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
