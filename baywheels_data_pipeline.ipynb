{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b0a273",
   "metadata": {},
   "source": [
    "Goals\n",
    "1. Download all zippped files and unzip csv files to 2 seperate folders. One for Ford and one for Lyft - Do in automated fashion if possible\n",
    "2. Combine each of the 10+ csv files into 2 big files, one for Ford and one for Lyft\n",
    "3. Push to AWS S3\n",
    "\n",
    "Bonus: Each month write a code that auto pulls the new zipped file from the cloud and appends it to our existing Lyft AWS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "135ea93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will utilize some code from my past web scraping project and tweak it for this project.\n",
    "#I will use selenium since that is what I have used in the past and is what I am familiar with\n",
    "\n",
    "#This currently looks up certain fields for you and enters them into the website. \n",
    "#Next would be to automate this to run through all 4 designations I want. Do that at end. Also make cleaner later.\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import math\n",
    "import regex as re \n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import boto3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed0fbbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_10500/3459515471.py:9: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chromeOptions)\n"
     ]
    }
   ],
   "source": [
    "#This will auto download all the code currently on baywheels website\n",
    "\n",
    "#set download path\n",
    "chromeOptions = webdriver.ChromeOptions()\n",
    "prefs = {\"download.default_directory\" : r\"C:\\Users\\gadde\\Desktop\\Data_Analytics_projects\\baywheels_analysis\\zipped_data\"}\n",
    "chromeOptions.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "#start chromedriver\n",
    "driver = webdriver.Chrome(chrome_options=chromeOptions)\n",
    "driver.get('https://s3.amazonaws.com/baywheels-data/index.html')\n",
    "#//*[@id=\"tbody-content\"]/tr[1]/td[1]/a\n",
    "time.sleep(1)\n",
    "\n",
    "#Note we have it hard set to 53. Ideally we could use a lenght of something to automatically determine this but I don't\n",
    "#know how to do that.\n",
    "for i in range(53):\n",
    "    download = driver.find_element(by=By.XPATH, value='//*[@id=\"tbody-content\"]/tr[' + str(i+1) + ']/td[1]/a')\n",
    "    download.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "223a35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let us go ahead and unzip all the files in the zipped_data folder\n",
    "for root, dirs, files in os.walk('zipped_data'):\n",
    "    for name in files:\n",
    "        with ZipFile(os.path.join(root, name), 'r') as zip_ref:\n",
    "            zip_ref.extractall('baywheels_data\\Ford')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975f48b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baywheels.data\n"
     ]
    }
   ],
   "source": [
    "#I just uploaded one years worth of data to an AWS S3 bucket. Let me check if I can access it here\n",
    "\n",
    "# Let's use Amazon S3\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "# Print out bucket names\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6897cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us see if we can download the data from the s3 bucket\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    Bucket=\"baywheels.data\", Key=\"2017-fordgobike-tripdata.csv\", Filename=\"aws_data/downloaded_from_s3.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
