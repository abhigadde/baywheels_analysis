{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbea3f1",
   "metadata": {},
   "source": [
    "Goals\n",
    "1. Download all zippped files and unzip csv files to 2 seperate folders. One for Ford and one for Lyft - Do in automated fashion if possible\n",
    "2. Combine each of the 10+ csv files into 2 big files, one for Ford and one for Lyft\n",
    "3. Push to AWS S3\n",
    "\n",
    "Bonus: Each month write a code that auto pulls the new zipped file from the cloud and appends it to our existing Lyft AWS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "135ea93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will utilize some code from my past web scraping project and tweak it for this project.\n",
    "#I will use selenium since that is what I have used in the past and is what I am familiar with\n",
    "\n",
    "#This currently looks up certain fields for you and enters them into the website. \n",
    "#Next would be to automate this to run through all 4 designations I want. Do that at end. Also make cleaner later.\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import math\n",
    "import regex as re \n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import boto3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed0fbbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadde\\AppData\\Local\\Temp/ipykernel_10500/713211868.py:9: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chromeOptions)\n"
     ]
    }
   ],
   "source": [
    "#This will auto download all the code currently on baywheels website\n",
    "\n",
    "#set download path\n",
    "chromeOptions = webdriver.ChromeOptions()\n",
    "prefs = {\"download.default_directory\" : r\"C:\\Users\\gadde\\Desktop\\Data_Analytics_projects\\baywheels_analysis\\zipped_data\"}\n",
    "chromeOptions.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "#start chromedriver\n",
    "driver = webdriver.Chrome(chrome_options=chromeOptions)\n",
    "driver.get('https://s3.amazonaws.com/baywheels-data/index.html')\n",
    "#//*[@id=\"tbody-content\"]/tr[1]/td[1]/a\n",
    "time.sleep(1)\n",
    "\n",
    "#Note we have it hard set to 53. Ideally we could use a lenght of something to automatically determine this but I don't\n",
    "#know how to do that.\n",
    "for i in range(53):\n",
    "    download = driver.find_element(by=By.XPATH, value='//*[@id=\"tbody-content\"]/tr[' + str(i+1) + ']/td[1]/a')\n",
    "    download.click()\n",
    "\n",
    "#Close out driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "223a35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let us go ahead and unzip all the files in the zipped_data folder\n",
    "for root, dirs, files in os.walk('zipped_data'):\n",
    "    for name in files:\n",
    "        if 'ford' in name:\n",
    "            with ZipFile(os.path.join(root, name), 'r') as zip_ref:\n",
    "                zip_ref.extractall('baywheels_data\\Ford')\n",
    "        elif 'baywheels' in name:\n",
    "            with ZipFile(os.path.join(root, name), 'r') as zip_ref:\n",
    "                zip_ref.extractall('baywheels_data\\Lyft')\n",
    "        else:\n",
    "            print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4675ed6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baywheels_data\\Ford\\2017-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201801-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201802-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201803-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201804-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201805-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201806-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201807-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201808-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201809-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201810-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201811-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201812-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201901-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201902-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201903-fordgobike-tripdata.csv\n",
      "baywheels_data\\Ford\\201904-fordgobike-tripdata.csv\n"
     ]
    }
   ],
   "source": [
    "#Now lets combine the multiple csv's in each of these folders into one large df and output that to a csv\n",
    "path = 'baywheels_data\\Ford'\n",
    "ford_file_names = []\n",
    "for files in os.listdir(path):\n",
    "    if 'csv' in files:\n",
    "        ford_data.append(os.path.join(path, files))\n",
    "        #print(os.path.join(path, files))\n",
    "        \n",
    "#Load the csv into a dataframe\n",
    "df_ford = pd.concat(map(pd.read_csv, ford_file_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d4da4c6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baywheels_data\\Lyft\\201905-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201906-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201907-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201908-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201909-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201910-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201911-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\201912-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202001-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202002-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202003-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202004-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202005-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202006-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202007-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202008-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202009-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202010-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202011-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202012-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202101-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202102-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202103-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202104-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202105-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202106-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202107-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202108-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202109-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202110-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202111-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202112-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202201-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202202-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202203-baywheels-tripdata.csv\n",
      "baywheels_data\\Lyft\\202204-baywheels-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gadde\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:294: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  op = _Concatenator(\n",
      "C:\\Users\\gadde\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:294: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  op = _Concatenator(\n",
      "C:\\Users\\gadde\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:294: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  op = _Concatenator(\n"
     ]
    }
   ],
   "source": [
    "#repeat above step for Lyft data\n",
    "path = 'baywheels_data\\Lyft'\n",
    "lyft_file_names = []\n",
    "for files in os.listdir(path):\n",
    "    if 'csv' in files:\n",
    "        lyft_file_names.append(os.path.join(path, files))\n",
    "        #print(os.path.join(path, files))\n",
    "        \n",
    "#Load the csv into a dataframe\n",
    "df_lyft = pd.concat(map(pd.read_csv, lyft_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d3edb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the ford and lyft data to a csv\n",
    "df_ford.to_csv(r'baywheels_data\\ford_data.csv')\n",
    "df_lyft.to_csv(r'baywheels_data\\lyft_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17e45178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lastly, let us upload these 2 large dataframes in an S3 bucket. We will upload this using the csv format.\n",
    "#I know that are probably more efficient file storage formats but since this data isn't huge csv should suffice\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "s3.upload_file(\n",
    "    Filename=r'baywheels_data\\ford_data.csv',\n",
    "    Bucket=\"baywheels.data\",\n",
    "    Key=\"ford_data.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e10118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for Lyft data\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "s3.upload_file(\n",
    "    Filename=r'baywheels_data\\lyft_data.csv',\n",
    "    Bucket=\"baywheels.data\",\n",
    "    Key=\"lyft_data.csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
